# Troubleshooting Runbook - Token Calculation & Tool Compatibility Issues

**ä½œæˆæ—¥**: 2025-08-20  
**ç›®çš„**: statusline vs ccusageå•é¡Œã§ç¢ºç«‹ã•ã‚ŒãŸå†ç™ºé˜²æ­¢ãƒ»ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æ‰‹é †ã®æ¨™æº–åŒ–  
**å¯¾è±¡**: å°†æ¥ç™ºç”Ÿã™ã‚‹é¡ä¼¼å•é¡Œã®è¿…é€Ÿè§£æ±º

## 1. ç·Šæ€¥å¯¾å¿œãƒ—ãƒ­ãƒˆã‚³ãƒ«

### 1.1 å•é¡Œæ¤œçŸ¥æ™‚ã®åˆå‹•å¯¾å¿œï¼ˆæœ€åˆã®30åˆ†ï¼‰

#### 1.1.1 ãƒˆãƒªã‚¢ãƒ¼ã‚¸ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
```
å•é¡Œå ±å‘Šãƒ»æ¤œçŸ¥
    â†“
ã€å·®ç•° < 5%ã€‘ â†’ æƒ…å ±åé›†ç¶™ç¶š â†’ å®šæœŸç›£è¦–
    â†“
ã€5% â‰¤ å·®ç•° < 20%ã€‘ â†’ ãƒ¬ãƒ™ãƒ«2å¯¾å¿œ â†’ èª¿æŸ»ãƒãƒ¼ãƒ æ‹›é›†
    â†“  
ã€20% â‰¤ å·®ç•° < 50%ã€‘ â†’ ãƒ¬ãƒ™ãƒ«3å¯¾å¿œ â†’ ç·Šæ€¥èª¿æŸ»ãƒ»ä¿®æ­£æ¤œè¨
    â†“
ã€å·®ç•° â‰¥ 50%ã€‘ â†’ ãƒ¬ãƒ™ãƒ«4å¯¾å¿œ â†’ å³åº§ã«ç·Šæ€¥å¯¾å¿œãƒãƒ¼ãƒ æ‹›é›†
```

#### 1.1.2 åˆå‹•ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ
```bash
#!/bin/bash
# ç·Šæ€¥è¨ºæ–­ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ5åˆ†ä»¥å†…ã§å®Ÿè¡Œï¼‰

echo "=== EMERGENCY DIAGNOSTIC SCRIPT ==="
echo "Timestamp: $(date)"

# 1. ä¸¡ãƒ„ãƒ¼ãƒ«ã®ç¾åœ¨å€¤å–å¾—
echo "1. Current Values Comparison:"
ccusage_tokens=$(npx ccusage@latest blocks --json 2>/dev/null | jq -r '.blocks[] | select(.isActive == true) | .totalTokens' 2>/dev/null || echo "ERROR")
statusline_tokens=$(echo '{"session_id":"test"}' | python3 statusline.py --show 4 2>/dev/null | grep -o '[0-9,]*' | head -1 | tr -d ',' 2>/dev/null || echo "ERROR")

echo "  ccusage: $ccusage_tokens tokens"
echo "  statusline: $statusline_tokens tokens"

if [[ "$ccusage_tokens" != "ERROR" && "$statusline_tokens" != "ERROR" ]]; then
    diff_absolute=$((statusline_tokens - ccusage_tokens))
    diff_percentage=$(echo "scale=1; ($diff_absolute * 100.0) / $ccusage_tokens" | bc 2>/dev/null || echo "CALC_ERROR")
    echo "  Difference: $diff_absolute tokens ($diff_percentage%)"
else
    echo "  ERROR: Failed to retrieve values"
fi

# 2. ã‚·ã‚¹ãƒ†ãƒ åŸºæœ¬ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
echo "2. System Health Check:"
echo "  Python available: $(which python3 >/dev/null && echo "OK" || echo "ERROR")"
echo "  ccusage available: $(which npx >/dev/null && echo "OK" || echo "ERROR")" 
echo "  statusline.py exists: $(test -f statusline.py && echo "OK" || echo "ERROR")"
echo "  Project files accessible: $(ls ~/.claude/projects/ >/dev/null 2>&1 && echo "OK" || echo "ERROR")"

# 3. æœ€è¿‘ã®å¤‰æ›´ç¢ºèª
echo "3. Recent Changes:"
echo "  Last statusline.py modification: $(stat -f "%Sm" statusline.py 2>/dev/null || echo "UNKNOWN")"
echo "  Recent git commits:"
git log --oneline -5 2>/dev/null || echo "  No git history available"

echo "=== END DIAGNOSTIC ==="
```

### 1.2 ãƒ¬ãƒ™ãƒ«åˆ¥å¯¾å¿œæ‰‹é †

#### ãƒ¬ãƒ™ãƒ«2å¯¾å¿œï¼ˆå·®ç•°5-20%ï¼‰
**æ‹…å½“**: é–‹ç™ºãƒãƒ¼ãƒ   
**ç›®æ¨™**: 24æ™‚é–“ä»¥å†…ã®åŸå› ç‰¹å®š

```bash
# ãƒ¬ãƒ™ãƒ«2èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
python3 -c "
import json
import sys
from datetime import datetime

# è©³ç´°æ¯”è¼ƒå®Ÿè¡Œ
def detailed_comparison():
    # æ™‚ç³»åˆ—ã§ã®å€¤å¤‰åŒ–ã‚’è¿½è·¡
    measurements = []
    for i in range(12):  # 1æ™‚é–“ã«ã‚ãŸã‚Š5åˆ†é–“éš”ã§æ¸¬å®š
        ccusage_val = get_ccusage_value()
        statusline_val = get_statusline_value()
        measurements.append({
            'timestamp': datetime.now(),
            'ccusage': ccusage_val,
            'statusline': statusline_val,
            'diff': statusline_val - ccusage_val if ccusage_val and statusline_val else None
        })
        time.sleep(300)  # 5åˆ†å¾…æ©Ÿ
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    return analyze_trend(measurements)

result = detailed_comparison()
print(json.dumps(result, indent=2))
"
```

#### ãƒ¬ãƒ™ãƒ«3å¯¾å¿œï¼ˆå·®ç•°20-50%ï¼‰
**æ‹…å½“**: ã‚·ãƒ‹ã‚¢é–‹ç™ºè€… + ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ  
**ç›®æ¨™**: 12æ™‚é–“ä»¥å†…ã®æ ¹æœ¬åŸå› ç‰¹å®šã¨ä¿®æ­£è¨ˆç”»ç­–å®š

#### ãƒ¬ãƒ™ãƒ«4å¯¾å¿œï¼ˆå·®ç•°â‰¥50%ï¼‰  
**æ‹…å½“**: ç·Šæ€¥å¯¾å¿œãƒãƒ¼ãƒ å…¨å“¡  
**ç›®æ¨™**: 2æ™‚é–“ä»¥å†…ã®ç·Šæ€¥æªç½®å®Ÿæ–½

## 2. æ ¹æœ¬åŸå› åˆ†æï¼ˆRCAï¼‰æ¨™æº–æ‰‹é †

### 2.1 ãƒ‡ãƒ¼ã‚¿åé›†ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ30åˆ†ï¼‰

#### 2.1.1 ç’°å¢ƒæƒ…å ±åé›†
```bash
#!/bin/bash
# ç’°å¢ƒæƒ…å ±åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

RCA_DIR="./rca_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$RCA_DIR"

echo "Collecting environmental data..."

# ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
{
    echo "=== SYSTEM INFORMATION ==="
    echo "Date: $(date)"
    echo "OS: $(uname -a)"
    echo "Python version: $(python3 --version 2>&1)"
    echo "Node.js version: $(node --version 2>&1)"
    echo "npm version: $(npm --version 2>&1)"
    echo ""
} > "$RCA_DIR/system_info.txt"

# ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±
{
    echo "=== TOOL VERSIONS ==="
    echo "ccusage version:"
    npx ccusage@latest --version 2>&1
    echo ""
    echo "statusline.py modification time:"
    stat -f "%Sm" statusline.py 2>&1
    echo ""
} >> "$RCA_DIR/system_info.txt"

# GitçŠ¶æ…‹
{
    echo "=== GIT STATUS ==="
    git status 2>&1
    echo ""
    echo "=== RECENT COMMITS ==="
    git log --oneline -10 2>&1
} > "$RCA_DIR/git_info.txt"

# ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«çŠ¶æ…‹
{
    echo "=== DATA FILES STATUS ==="
    echo "Project directories:"
    ls -la ~/.claude/projects/ 2>&1
    echo ""
    echo "Recent transcript files (last 5):"
    find ~/.claude/projects/ -name "*.jsonl" -type f -exec stat -f "%Sm %N" {} \; 2>/dev/null | sort -r | head -5
} > "$RCA_DIR/data_info.txt"

echo "Environmental data collected in $RCA_DIR/"
```

#### 2.1.2 å‹•ä½œãƒ­ã‚°åé›†
```python
# è©³ç´°å‹•ä½œãƒ­ã‚°å–å¾—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
import logging
import json
import subprocess
import sys
from datetime import datetime

# ãƒ‡ãƒãƒƒã‚°ãƒ¬ãƒ™ãƒ«ã®ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(f'rca_debug_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log'),
        logging.StreamHandler(sys.stdout)
    ]
)

def collect_detailed_logs():
    """è©³ç´°ãªãƒ‡ãƒãƒƒã‚°æƒ…å ±åé›†"""
    
    logging.info("Starting detailed log collection...")
    
    # ccusageã®è©³ç´°å®Ÿè¡Œãƒ­ã‚°
    try:
        result = subprocess.run(['npx', 'ccusage@latest', 'blocks', '--json'], 
                              capture_output=True, text=True, timeout=30)
        logging.info(f"ccusage stdout: {result.stdout}")
        if result.stderr:
            logging.warning(f"ccusage stderr: {result.stderr}")
    except Exception as e:
        logging.error(f"Failed to execute ccusage: {e}")
    
    # statuslineã®è©³ç´°å®Ÿè¡Œãƒ­ã‚°  
    try:
        process = subprocess.Popen(['python3', 'statusline.py', '--show', '4'], 
                                 stdin=subprocess.PIPE, 
                                 stdout=subprocess.PIPE, 
                                 stderr=subprocess.PIPE, 
                                 text=True)
        stdout, stderr = process.communicate(input='{"session_id":"debug_test"}', timeout=30)
        
        logging.info(f"statusline stdout: {stdout}")
        if stderr:
            logging.warning(f"statusline stderr: {stderr}")
            
    except Exception as e:
        logging.error(f"Failed to execute statusline: {e}")

if __name__ == "__main__":
    collect_detailed_logs()
```

### 2.2 åˆ†æãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ60åˆ†ï¼‰

#### 2.2.1 å·®ç•°ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ
```python
def analyze_discrepancy_pattern():
    """å·®ç•°ãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµ±è¨ˆçš„åˆ†æ"""
    
    import numpy as np
    import pandas as pd
    from scipy import stats
    
    # è¤‡æ•°å›æ¸¬å®šã«ã‚ˆã‚‹çµ±è¨ˆåˆ†æ
    measurements = []
    for i in range(20):  # 20å›æ¸¬å®š
        ccusage_val = get_ccusage_measurement()
        statusline_val = get_statusline_measurement()
        timestamp = datetime.now()
        
        measurements.append({
            'timestamp': timestamp,
            'ccusage': ccusage_val,
            'statusline': statusline_val,
            'difference': statusline_val - ccusage_val,
            'ratio': statusline_val / ccusage_val if ccusage_val > 0 else None
        })
        
        time.sleep(10)  # 10ç§’é–“éš”
    
    df = pd.DataFrame(measurements)
    
    analysis = {
        'statistical_summary': {
            'mean_difference': df['difference'].mean(),
            'std_difference': df['difference'].std(),
            'mean_ratio': df['ratio'].mean(),
            'std_ratio': df['ratio'].std(),
            'consistency': df['ratio'].std() < 0.1  # æ¯”ç‡ã®æ¨™æº–åå·®ãŒ0.1ä»¥ä¸‹ãªã‚‰ä¸€è²«ã—ã¦ã„ã‚‹
        },
        'trend_analysis': {
            'difference_trend': analyze_trend(df['timestamp'], df['difference']),
            'is_increasing': df['difference'].corr(range(len(df))) > 0.5,
            'is_stable': df['difference'].std() / df['difference'].mean() < 0.1
        },
        'categorization': categorize_discrepancy_type(df)
    }
    
    return analysis

def categorize_discrepancy_type(df):
    """å·®ç•°ã‚¿ã‚¤ãƒ—ã®åˆ†é¡"""
    mean_ratio = df['ratio'].mean()
    ratio_std = df['ratio'].std()
    
    if ratio_std < 0.05:  # éå¸¸ã«ä¸€è²«ã—ã¦ã„ã‚‹
        if abs(mean_ratio - 1.0) < 0.01:
            return "IDENTICAL"
        elif abs(mean_ratio - 2.0) < 0.1:
            return "DOUBLE_COUNTING"  # 2å€ã«ãªã£ã¦ã„ã‚‹
        elif mean_ratio > 1.5:
            return "SYSTEMATIC_OVERCOUNTING"
        elif mean_ratio < 0.5:
            return "SYSTEMATIC_UNDERCOUNTING"
        else:
            return "CONSISTENT_BIAS"
    else:
        return "INCONSISTENT_CALCULATION"
```

#### 2.2.2 ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ™ãƒ«åˆ†æ
```bash
# ã‚³ãƒ¼ãƒ‰å·®åˆ†åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
#!/bin/bash

echo "=== CODE-LEVEL ANALYSIS ==="

# æœ€è¿‘ã®å¤‰æ›´ç®‡æ‰€ç‰¹å®š
echo "1. Recent changes in token calculation code:"
git log -p --since="1 week ago" -- statusline.py | grep -A5 -B5 -E "(token|usage|calculate)" || echo "No recent token-related changes"

echo ""

# ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—é–¢é€£é–¢æ•°ã®æŠ½å‡º
echo "2. Current token calculation functions:"
grep -n -A10 -B2 "def.*token" statusline.py | head -50

echo ""

# usage field ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ç¢ºèª
echo "3. Usage field access patterns:"
grep -n "usage\." statusline.py | head -20
grep -n "\.get.*token" statusline.py | head -20

echo ""

# ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ¤œå‡º
echo "4. Suspicious patterns:"
echo "  - Use of 'or' in token calculation:"
grep -n -C3 "\.get.*or.*\.get" statusline.py | grep -i token
echo "  - Fallback logic in cache token handling:"
grep -n -C3 "cache.*or.*cache" statusline.py
```

### 2.3 ä»®èª¬æ¤œè¨¼ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆ90åˆ†ï¼‰

#### 2.3.1 ä»®èª¬é§†å‹•å‹ãƒ†ã‚¹ãƒˆ
```python
def test_hypotheses():
    """ä¸»è¦ä»®èª¬ã®ä½“ç³»çš„æ¤œè¨¼"""
    
    hypotheses = [
        {
            'name': 'double_counting_cache_tokens',
            'description': 'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³ã®äºŒé‡ã‚«ã‚¦ãƒ³ãƒˆ',
            'test_function': test_cache_double_counting,
            'expected_evidence': 'ãƒ•ã‚¡ãƒ¼ãƒ å†…tokens increase by factor of 2'
        },
        {
            'name': 'field_name_mismatch', 
            'description': 'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰åã®ä¸æ•´åˆ',
            'test_function': test_field_name_issues,
            'expected_evidence': 'Different field access patterns'
        },
        {
            'name': 'deduplication_difference',
            'description': 'é‡è¤‡é™¤å»ãƒ­ã‚¸ãƒƒã‚¯ã®é•ã„',
            'test_function': test_deduplication_logic,
            'expected_evidence': 'Different message counts processed'
        },
        {
            'name': 'time_window_mismatch',
            'description': 'æ™‚é–“çª“ã®ä¸ä¸€è‡´',
            'test_function': test_time_window_alignment,
            'expected_evidence': 'Different time range processing'
        }
    ]
    
    results = {}
    
    for hypothesis in hypotheses:
        print(f"Testing hypothesis: {hypothesis['name']}")
        
        try:
            test_result = hypothesis['test_function']()
            results[hypothesis['name']] = {
                'tested': True,
                'evidence_found': test_result['evidence_found'],
                'confidence': test_result['confidence'],
                'details': test_result['details']
            }
            
            if test_result['evidence_found']:
                print(f"  âœ… Evidence found (confidence: {test_result['confidence']})")
            else:
                print(f"  âŒ No evidence found")
                
        except Exception as e:
            results[hypothesis['name']] = {
                'tested': False,
                'error': str(e)
            }
            print(f"  âš ï¸  Test failed: {e}")
    
    return results

def test_cache_double_counting():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³äºŒé‡ã‚«ã‚¦ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ"""
    
    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ
    test_usage_data = {
        'input_tokens': 100,
        'output_tokens': 200,
        'cache_creation_input_tokens': 1000,
        'cache_creation': {
            'ephemeral_5m_input_tokens': 1000  # åŒã˜å€¤
        }
    }
    
    # ç¾åœ¨ã®å®Ÿè£…ã§ãƒ†ã‚¹ãƒˆ
    current_result = get_total_tokens(test_usage_data)
    
    # æ­£ã—ã„å®Ÿè£…ã§ãƒ†ã‚¹ãƒˆ
    correct_result = get_total_tokens_correct(test_usage_data)
    
    evidence_found = current_result != correct_result
    confidence = 1.0 if evidence_found else 0.0
    
    return {
        'evidence_found': evidence_found,
        'confidence': confidence,
        'details': {
            'current_result': current_result,
            'correct_result': correct_result,
            'difference': current_result - correct_result
        }
    }
```

## 3. ä¿®æ­£å®Ÿè£…ã‚¬ã‚¤ãƒ‰

### 3.1 æ®µéšçš„ä¿®æ­£ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ

#### 3.1.1 ä¿®æ­£ãƒ—ãƒ©ãƒ³ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
```python
class FixImplementationPlan:
    
    def __init__(self, root_cause):
        self.root_cause = root_cause
        self.phases = self.design_fix_phases()
        
    def design_fix_phases(self):
        """ä¿®æ­£ãƒ•ã‚§ãƒ¼ã‚ºã®è¨­è¨ˆ"""
        
        base_phases = [
            {
                'name': 'validation_setup',
                'description': 'ä¿®æ­£å‰å¾Œã®æ¤œè¨¼ç’°å¢ƒæ§‹ç¯‰', 
                'duration_minutes': 15,
                'rollback_possible': True
            },
            {
                'name': 'core_logic_fix',
                'description': 'æ ¸å¿ƒãƒ­ã‚¸ãƒƒã‚¯ã®ä¿®æ­£',
                'duration_minutes': 30,
                'rollback_possible': True  
            },
            {
                'name': 'integration_test',
                'description': 'çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ',
                'duration_minutes': 20,
                'rollback_possible': True
            },
            {
                'name': 'production_validation',
                'description': 'æœ¬ç•ªç’°å¢ƒã§ã®æ¤œè¨¼',
                'duration_minutes': 15,
                'rollback_possible': True
            }
        ]
        
        # æ ¹æœ¬åŸå› ã«å¿œã˜ãŸç‰¹æ®Šãƒ•ã‚§ãƒ¼ã‚ºã®è¿½åŠ 
        if 'double_counting' in self.root_cause:
            base_phases.insert(1, {
                'name': 'field_access_refactor',
                'description': 'ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚¢ã‚¯ã‚»ã‚¹ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ä¿®æ­£',
                'duration_minutes': 45,
                'rollback_possible': True
            })
            
        return base_phases
```

#### 3.1.2 ä¿®æ­£å‰å¾Œæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# ä¿®æ­£å‰å¾Œã®è‡ªå‹•æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

VALIDATION_DIR="./validation_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$VALIDATION_DIR"

echo "=== PRE-FIX VALIDATION ==="

# ä¿®æ­£å‰ã®å€¤å–å¾—
ccusage_before=$(npx ccusage@latest blocks --json | jq -r '.blocks[] | select(.isActive == true) | .totalTokens')
statusline_before=$(echo '{"session_id":"test"}' | python3 statusline.py --show 4 2>/dev/null | grep -o '[0-9,]*' | head -1 | tr -d ',')

echo "ccusage (before): $ccusage_before"
echo "statusline (before): $statusline_before"

if [[ "$ccusage_before" != "" && "$statusline_before" != "" ]]; then
    diff_before=$((statusline_before - ccusage_before))
    diff_pct_before=$(echo "scale=1; ($diff_before * 100.0) / $ccusage_before" | bc)
    echo "Difference (before): $diff_before tokens ($diff_pct_before%)"
else
    echo "ERROR: Could not get baseline measurements"
    exit 1
fi

# çµæœä¿å­˜
{
    echo "timestamp: $(date)"
    echo "ccusage_before: $ccusage_before"
    echo "statusline_before: $statusline_before" 
    echo "difference_before: $diff_before"
    echo "percentage_before: $diff_pct_before"
} > "$VALIDATION_DIR/baseline.txt"

echo ""
echo "*** APPLY YOUR FIX NOW ***"
echo "Press ENTER when fix is applied..."
read

echo ""
echo "=== POST-FIX VALIDATION ==="

# ä¿®æ­£å¾Œã®å€¤å–å¾—
ccusage_after=$(npx ccusage@latest blocks --json | jq -r '.blocks[] | select(.isActive == true) | .totalTokens')
statusline_after=$(echo '{"session_id":"test"}' | python3 statusline.py --show 4 2>/dev/null | grep -o '[0-9,]*' | head -1 | tr -d ',')

echo "ccusage (after): $ccusage_after"
echo "statusline (after): $statusline_after"

if [[ "$ccusage_after" != "" && "$statusline_after" != "" ]]; then
    diff_after=$((statusline_after - ccusage_after))
    diff_pct_after=$(echo "scale=1; ($diff_after * 100.0) / $ccusage_after" | bc)
    echo "Difference (after): $diff_after tokens ($diff_pct_after%)"
    
    # æ”¹å–„ç‡è¨ˆç®—
    improvement=$(echo "scale=1; $diff_pct_before - $diff_pct_after" | bc)
    echo "Improvement: $improvement percentage points"
    
    # æˆåŠŸåˆ¤å®š
    if (( $(echo "$diff_pct_after < 5.0" | bc -l) )); then
        echo "âœ… SUCCESS: Difference within acceptable range (<5%)"
        exit 0
    else
        echo "âš ï¸  WARNING: Difference still significant (â‰¥5%)"
        exit 1
    fi
else
    echo "âŒ ERROR: Could not get post-fix measurements"
    exit 2
fi
```

### 3.2 ã‚ˆãã‚ã‚‹ä¿®æ­£ãƒ‘ã‚¿ãƒ¼ãƒ³

#### 3.2.1 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒˆãƒ¼ã‚¯ãƒ³äºŒé‡ã‚«ã‚¦ãƒ³ãƒˆä¿®æ­£
```python
# ä¿®æ­£å‰ï¼ˆå•é¡Œã‚ã‚Šï¼‰
def get_total_tokens_problematic(usage_data):
    cache_creation = (
        usage_data.get('cache_creation_input_tokens', 0) or
        usage_data.get('cache_creation', {}).get('ephemeral_5m_input_tokens', 0)
    )
    # â†‘ `or`æ¼”ç®—å­ã«ã‚ˆã‚Šä¸¡æ–¹ãŒéã‚¼ãƒ­ã®å ´åˆã«æœ€åˆã®å€¤ã®ã¿ä½¿ç”¨ã€
    #   ã—ã‹ã—å®Ÿéš›ã«ã¯åŒã˜å€¤ãŒæ ¼ç´ã•ã‚Œã¦ã„ã‚‹ãŸã‚å•é¡Œãªã—ï¼Ÿ
    #   å®Ÿéš›ã®å•é¡Œã¯åˆ¥ã®ç®‡æ‰€ã«ã‚ã‚‹å¯èƒ½æ€§

# ä¿®æ­£å¾Œï¼ˆccusageäº’æ›ï¼‰
def get_total_tokens_fixed(usage_data):
    """ccusageã¨å®Œå…¨äº’æ›ã®ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—"""
    if not usage_data:
        return 0
    
    input_tokens = usage_data.get('input_tokens', 0)
    output_tokens = usage_data.get('output_tokens', 0)
    
    # ccusageã®æ¡ä»¶åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã‚’æ­£ç¢ºã«å†ç¾
    if 'cache_creation_input_tokens' in usage_data:
        cache_creation = usage_data['cache_creation_input_tokens']
    else:
        # ccusageã¯ cacheCreationTokens ã‚’ãƒã‚§ãƒƒã‚¯ã™ã‚‹ãŒã€
        # Claude Codeã§ã¯ cache_creation.ephemeral_5m_input_tokens ã‚’ä½¿ç”¨
        cache_creation = usage_data.get('cache_creation', {}).get('ephemeral_5m_input_tokens', 0)
    
    if 'cache_read_input_tokens' in usage_data:
        cache_read = usage_data['cache_read_input_tokens']
    else:
        cache_read = usage_data.get('cache_read', {}).get('ephemeral_5m_input_tokens', 0)
    
    return input_tokens + output_tokens + cache_creation + cache_read
```

#### 3.2.2 é‡è¤‡é™¤å»ãƒ­ã‚¸ãƒƒã‚¯ä¿®æ­£
```python
# ccusageäº’æ›ã®é‡è¤‡é™¤å»
def create_message_hash_ccusage_compatible(message):
    """ccusageäº’æ›ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆ"""
    
    # ccusageã®hashç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ã‚’å†ç¾
    message_id = message.get('message', {}).get('id')  # ãƒã‚¹ãƒˆã•ã‚ŒãŸã‚¢ã‚¯ã‚»ã‚¹
    request_id = message.get('requestId')
    
    if message_id and request_id:
        return f"{message_id}:{request_id}"
    else:
        return None  # ccusageã¯è©²å½“ã—ãªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å‡¦ç†ã—ãªã„

# ä¿®æ­£ç‰ˆã®é‡è¤‡é™¤å»å®Ÿè£…
def deduplicate_messages_ccusage_style(messages):
    """ccusageæ–¹å¼ã®é‡è¤‡é™¤å»"""
    
    seen_hashes = set()
    deduplicated = []
    duplicate_count = 0
    
    for message in messages:
        message_hash = create_message_hash_ccusage_compatible(message)
        
        if message_hash is None:
            # ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆã§ããªã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ccusageã§ã¯ç„¡è¦–
            continue
            
        if message_hash not in seen_hashes:
            seen_hashes.add(message_hash)
            deduplicated.append(message)
        else:
            duplicate_count += 1
    
    return deduplicated, duplicate_count
```

## 4. äºˆé˜²çš„ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

### 4.1 ç¶™ç¶šçš„ç›£è¦–ã®è¨­å®š

#### 4.1.1 è‡ªå‹•ç›£è¦–ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
#!/usr/bin/env python3
"""
ç¶™ç¶šçš„äº’æ›æ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
å®šæœŸçš„ã«ccusageã¨statuslineã®å·®ç•°ã‚’ç›£è¦–ã—ã€é–¾å€¤ã‚’è¶…ãˆãŸå ´åˆã«ã‚¢ãƒ©ãƒ¼ãƒˆ
"""

import time
import json
import subprocess
import logging
from datetime import datetime
import smtplib
from email.mime.text import MIMEText

class CompatibilityMonitor:
    
    def __init__(self, config_file='monitoring_config.json'):
        with open(config_file) as f:
            self.config = json.load(f)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('compatibility_monitor.log'),
                logging.StreamHandler()
            ]
        )
        
    def measure_current_difference(self):
        """ç¾åœ¨ã®å·®ç•°ã‚’æ¸¬å®š"""
        try:
            # ccusageå€¤å–å¾—
            ccusage_result = subprocess.run(
                ['npx', 'ccusage@latest', 'blocks', '--json'],
                capture_output=True, text=True, timeout=30
            )
            ccusage_data = json.loads(ccusage_result.stdout)
            ccusage_tokens = next(
                (block['totalTokens'] for block in ccusage_data['blocks'] if block.get('isActive')),
                None
            )
            
            # statuslineå€¤å–å¾—
            statusline_result = subprocess.run(
                ['python3', 'statusline.py', '--show', '4'],
                input='{"session_id":"monitoring"}',
                capture_output=True, text=True, timeout=30
            )
            # statuslineå‡ºåŠ›ã‹ã‚‰æ•°å€¤æŠ½å‡º
            import re
            statusline_match = re.search(r'(\d{1,3}(?:,\d{3})*)\s+token', statusline_result.stdout)
            statusline_tokens = int(statusline_match.group(1).replace(',', '')) if statusline_match else None
            
            if ccusage_tokens and statusline_tokens:
                difference = statusline_tokens - ccusage_tokens
                percentage = (difference / ccusage_tokens) * 100
                
                return {
                    'timestamp': datetime.now(),
                    'ccusage_tokens': ccusage_tokens,
                    'statusline_tokens': statusline_tokens,
                    'difference': difference,
                    'percentage': percentage,
                    'success': True
                }
            else:
                return {'success': False, 'error': 'Failed to extract token values'}
                
        except Exception as e:
            return {'success': False, 'error': str(e)}
    
    def evaluate_alert_level(self, measurement):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ã®åˆ¤å®š"""
        if not measurement['success']:
            return 'ERROR'
        
        percentage = abs(measurement['percentage'])
        
        if percentage >= 50:
            return 'CRITICAL'
        elif percentage >= 20:
            return 'WARNING'
        elif percentage >= 5:
            return 'INFO'
        else:
            return 'OK'
    
    def send_alert(self, level, measurement):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡"""
        
        alert_config = self.config['alerts'][level.lower()]
        
        if not alert_config.get('enabled', False):
            return
            
        message = f"""
Compatibility Alert - Level {level}

Timestamp: {measurement['timestamp']}
ccusage tokens: {measurement['ccusage_tokens']:,}
statusline tokens: {measurement['statusline_tokens']:,}
Difference: {measurement['difference']:,} tokens ({measurement['percentage']:.1f}%)

Alert threshold: {alert_config.get('threshold', 'N/A')}%

Please investigate immediately.
"""
        
        # Slacké€šçŸ¥
        if alert_config.get('slack_enabled'):
            self.send_slack_alert(message, level)
            
        # Emailé€šçŸ¥
        if alert_config.get('email_enabled'):
            self.send_email_alert(message, level, alert_config['email_recipients'])
    
    def run_monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—ã®å®Ÿè¡Œ"""
        
        logging.info("Starting compatibility monitoring...")
        
        while True:
            try:
                measurement = self.measure_current_difference()
                alert_level = self.evaluate_alert_level(measurement)
                
                logging.info(f"Measurement: {alert_level} - "
                           f"Difference: {measurement.get('percentage', 'N/A'):.1f}%")
                
                if alert_level != 'OK':
                    self.send_alert(alert_level, measurement)
                    
                # æ¸¬å®šçµæœã®è¨˜éŒ²
                self.record_measurement(measurement, alert_level)
                
                # æ¬¡å›æ¸¬å®šã¾ã§å¾…æ©Ÿ
                time.sleep(self.config['monitoring']['interval_seconds'])
                
            except KeyboardInterrupt:
                logging.info("Monitoring stopped by user")
                break
            except Exception as e:
                logging.error(f"Monitoring loop error: {e}")
                time.sleep(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

if __name__ == "__main__":
    monitor = CompatibilityMonitor()
    monitor.run_monitoring_loop()
```

#### 4.1.2 ç›£è¦–è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```json
{
  "monitoring": {
    "interval_seconds": 300,
    "retention_days": 30
  },
  "alerts": {
    "critical": {
      "enabled": true,
      "threshold": 50,
      "slack_enabled": true,
      "email_enabled": true,
      "email_recipients": ["dev-team@company.com", "on-call@company.com"]
    },
    "warning": {
      "enabled": true, 
      "threshold": 20,
      "slack_enabled": true,
      "email_enabled": false
    },
    "info": {
      "enabled": true,
      "threshold": 5,
      "slack_enabled": false,
      "email_enabled": false
    },
    "error": {
      "enabled": true,
      "slack_enabled": true,
      "email_enabled": true,
      "email_recipients": ["dev-team@company.com"]
    }
  }
}
```

### 4.2 æ—©æœŸè­¦æˆ’ã‚·ã‚¹ãƒ†ãƒ 

#### 4.2.1 ãƒˆãƒ¬ãƒ³ãƒ‰ç•°å¸¸æ¤œå‡º
```python
def detect_trend_anomalies(measurement_history, lookback_hours=24):
    """ãƒˆãƒ¬ãƒ³ãƒ‰ç•°å¸¸ã®æ¤œå‡º"""
    
    import numpy as np
    from scipy import stats
    
    if len(measurement_history) < 10:
        return {'anomaly_detected': False, 'reason': 'Insufficient data'}
    
    # ç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
    recent_data = [m for m in measurement_history 
                   if (datetime.now() - m['timestamp']).total_seconds() < lookback_hours * 3600]
    
    percentages = [m['percentage'] for m in recent_data]
    
    # çµ±è¨ˆçš„ç•°å¸¸æ¤œå‡º
    z_scores = np.abs(stats.zscore(percentages))
    outliers = z_scores > 2.5  # 2.5Ïƒã‚’è¶…ãˆã‚‹å€¤
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
    if len(percentages) >= 5:
        slope, _, r_value, p_value, _ = stats.linregress(range(len(percentages)), percentages)
        
        trend_anomaly = {
            'anomaly_detected': False,
            'reasons': []
        }
        
        # æ€¥æ¿€ãªå¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰
        if slope > 1.0 and p_value < 0.05:
            trend_anomaly['anomaly_detected'] = True
            trend_anomaly['reasons'].append(f'Rapid increasing trend: {slope:.2f}%/measurement')
        
        # çµ±è¨ˆçš„å¤–ã‚Œå€¤ã®å­˜åœ¨  
        if np.sum(outliers) > len(percentages) * 0.2:
            trend_anomaly['anomaly_detected'] = True
            trend_anomaly['reasons'].append(f'Statistical outliers: {np.sum(outliers)}/{len(percentages)} measurements')
        
        # åˆ†æ•£ã®æ€¥æ¿€ãªå¢—åŠ 
        recent_std = np.std(percentages[-5:]) if len(percentages) >= 5 else 0
        historical_std = np.std(percentages[:-5]) if len(percentages) >= 10 else recent_std
        
        if recent_std > historical_std * 2:
            trend_anomaly['anomaly_detected'] = True
            trend_anomaly['reasons'].append(f'Increased volatility: {recent_std:.2f} vs {historical_std:.2f}')
        
        return trend_anomaly
    
    return {'anomaly_detected': False, 'reason': 'Insufficient data for trend analysis'}
```

## 5. äº‹å¾Œå¯¾å¿œãƒ»å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

### 5.1 ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆè¨˜éŒ²ã‚·ã‚¹ãƒ†ãƒ 

#### 5.1.1 æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
```python
class IncidentReportGenerator:
    
    def __init__(self):
        self.template = self.load_incident_template()
    
    def generate_incident_report(self, incident_data):
        """æ§‹é€ åŒ–ã•ã‚ŒãŸã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        report = {
            'incident_id': incident_data.get('id', f"INC_{datetime.now().strftime('%Y%m%d_%H%M%S')}"),
            'summary': {
                'title': incident_data.get('title', 'Token Calculation Discrepancy'),
                'severity': incident_data.get('severity', 'UNKNOWN'),
                'affected_systems': ['statusline', 'ccusage_compatibility'],
                'detection_time': incident_data.get('detection_time'),
                'resolution_time': incident_data.get('resolution_time'),
                'total_duration': self.calculate_duration(
                    incident_data.get('detection_time'),
                    incident_data.get('resolution_time')
                )
            },
            'impact_assessment': {
                'business_impact': incident_data.get('business_impact', 'LOW'),
                'user_impact': incident_data.get('user_impact', 'MINIMAL'),
                'data_accuracy_impact': incident_data.get('accuracy_impact', 'HIGH')
            },
            'timeline': self.structure_timeline(incident_data.get('timeline', [])),
            'root_cause_analysis': {
                'primary_cause': incident_data.get('root_cause'),
                'contributing_factors': incident_data.get('contributing_factors', []),
                'why_not_detected_earlier': incident_data.get('detection_failure_reason')
            },
            'resolution': {
                'actions_taken': incident_data.get('resolution_actions', []),
                'code_changes': incident_data.get('code_changes', []),
                'verification_method': incident_data.get('verification_method')
            },
            'prevention_measures': {
                'immediate_actions': incident_data.get('immediate_prevention', []),
                'long_term_improvements': incident_data.get('long_term_prevention', []),
                'monitoring_enhancements': incident_data.get('monitoring_improvements', [])
            },
            'lessons_learned': incident_data.get('lessons_learned', []),
            'action_items': self.extract_action_items(incident_data)
        }
        
        return report
    
    def extract_action_items(self, incident_data):
        """ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ ã®æŠ½å‡º"""
        
        action_items = []
        
        # äºˆé˜²æªç½®ã‹ã‚‰ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ 
        for action in incident_data.get('immediate_prevention', []):
            action_items.append({
                'description': action,
                'type': 'prevention',
                'priority': 'HIGH',
                'due_date': (datetime.now() + timedelta(days=7)).isoformat(),
                'owner': 'dev_team'
            })
        
        # ç›£è¦–æ”¹å–„ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚¢ã‚¤ãƒ†ãƒ   
        for improvement in incident_data.get('monitoring_improvements', []):
            action_items.append({
                'description': improvement,
                'type': 'monitoring',
                'priority': 'MEDIUM',
                'due_date': (datetime.now() + timedelta(days=14)).isoformat(),
                'owner': 'devops_team'
            })
        
        return action_items
```

### 5.2 ç¶™ç¶šçš„æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹

#### 5.2.1 å››åŠæœŸæŒ¯ã‚Šè¿”ã‚Šãƒ¬ãƒãƒ¼ãƒˆ
```python
def generate_quarterly_retrospective():
    """å››åŠæœŸã”ã¨ã®æŒ¯ã‚Šè¿”ã‚Šãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    
    # éå»3ãƒ¶æœˆã®ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿åé›†
    incidents = load_incidents_last_quarter()
    
    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹é›†è¨ˆ
    metrics = {
        'total_incidents': len(incidents),
        'by_severity': count_by_severity(incidents),
        'by_root_cause': count_by_root_cause(incidents),
        'average_detection_time': calculate_average_detection_time(incidents),
        'average_resolution_time': calculate_average_resolution_time(incidents),
        'prevention_effectiveness': calculate_prevention_effectiveness(incidents)
    }
    
    # å‚¾å‘åˆ†æ
    trends = {
        'incident_frequency_trend': analyze_frequency_trend(incidents),
        'severity_trend': analyze_severity_trend(incidents),
        'resolution_time_trend': analyze_resolution_time_trend(incidents)
    }
    
    # æ”¹å–„ææ¡ˆ
    recommendations = generate_improvement_recommendations(metrics, trends)
    
    return {
        'period': 'Q4 2025',
        'metrics': metrics,
        'trends': trends,
        'top_issues': identify_top_recurring_issues(incidents),
        'success_stories': identify_success_stories(incidents),
        'recommendations': recommendations,
        'next_quarter_goals': define_next_quarter_goals(recommendations)
    }
```

## 6. ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆãƒ»ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆé›†

### 6.1 ç·Šæ€¥å¯¾å¿œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

```markdown
# ğŸš¨ ç·Šæ€¥å¯¾å¿œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ - Token Calculation Issue

## Phase 1: Initial Assessment (0-30 minutes)
- [ ] Confirm the issue is reproducible
- [ ] Measure current difference percentage: _____%
- [ ] Check if both tools are accessible and working
- [ ] Verify recent code changes in git log
- [ ] Determine severity level: [INFO / WARNING / CRITICAL / EMERGENCY]
- [ ] Notify appropriate stakeholders based on severity

## Phase 2: Quick Diagnostics (30-60 minutes)
- [ ] Run emergency diagnostic script
- [ ] Collect environmental information
- [ ] Check for recent ccusage version updates
- [ ] Verify transcript file accessibility
- [ ] Rule out infrastructure issues

## Phase 3: Root Cause Investigation (1-3 hours)
- [ ] Run hypothesis-driven testing
- [ ] Analyze code for suspicious patterns
- [ ] Compare field access logic between tools
- [ ] Test with isolated data samples
- [ ] Document findings with evidence

## Phase 4: Fix Implementation (30-90 minutes)
- [ ] Design fix based on root cause
- [ ] Implement fix with proper testing
- [ ] Run pre/post-fix validation
- [ ] Verify improvement meets target (<5% difference)
- [ ] Deploy to production

## Phase 5: Verification & Monitoring (30 minutes)
- [ ] Confirm fix effectiveness in production
- [ ] Set up enhanced monitoring
- [ ] Update documentation
- [ ] Schedule follow-up checks
- [ ] Close incident with proper documentation

**Emergency Contacts:**
- Dev Team Lead: ________________
- On-Call Engineer: ________________
- System Administrator: ________________
```

### 6.2 RCAãƒ¬ãƒãƒ¼ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```markdown
# Root Cause Analysis Report

**Incident ID:** INC_YYYYMMDD_HHMMSS  
**Date:** YYYY-MM-DD  
**Prepared by:** [Name]  
**Review by:** [Senior Engineer/Architect]

## Executive Summary
- **Issue:** Brief description of the compatibility issue
- **Impact:** Business/technical impact assessment  
- **Root Cause:** One-sentence root cause summary
- **Resolution:** High-level resolution approach
- **Prevention:** Key prevention measures implemented

## Incident Timeline

| Time | Event | Impact | Action Taken |
|------|-------|---------|--------------|
| HH:MM | Issue first detected | Monitoring alerts triggered | Investigation started |
| HH:MM | Root cause identified | Development team assigned | Fix implementation began |
| HH:MM | Fix implemented | Testing initiated | Validation performed |
| HH:MM | Resolution verified | Issue resolved | Monitoring enhanced |

## Technical Analysis

### Environment Details
- **statusline version:** [commit hash / date]
- **ccusage version:** [npm version]
- **System environment:** [OS, Python, Node.js versions]
- **Data scope:** [number of transcript files, date range]

### Root Cause Deep Dive
**Primary Cause:** [Detailed technical explanation]

**Evidence:**
1. [Specific evidence item 1]
2. [Specific evidence item 2]  
3. [Code samples, data examples, calculations]

**Contributing Factors:**
1. [Factor 1: why it wasn't caught earlier]
2. [Factor 2: what made it manifest now]

### Fix Implementation
**Solution Approach:** [Technical solution description]

**Code Changes:** [List of modified files and functions]

**Before/After Comparison:**
- Before: statusline=XXX, ccusage=YYY (Z% difference)
- After: statusline=AAA, ccusage=BBB (C% difference)
- Improvement: [% improvement achieved]

## Prevention Measures

### Immediate Actions (Next 7 days)
1. [Specific preventive action 1] - Owner: [Name] - Due: [Date]
2. [Specific preventive action 2] - Owner: [Name] - Due: [Date]

### Long-term Improvements (Next 30-90 days)  
1. [Strategic improvement 1] - Owner: [Team] - Due: [Date]
2. [Strategic improvement 2] - Owner: [Team] - Due: [Date]

### Process Improvements
1. [Monitoring enhancement]
2. [Testing improvement]  
3. [Documentation update]

## Lessons Learned
1. **Technical:** [Key technical insight]
2. **Process:** [Process improvement identified]
3. **Communication:** [Communication enhancement needed]

## Success Factors
- [What went well during the incident response]
- [Effective practices to continue]

---
**Follow-up Review Scheduled:** [Date]  
**Next Quarterly Review:** [Date]
```

---

**ã“ã®Runbookã®ä½¿ç”¨æ–¹æ³•**: å•é¡Œç™ºç”Ÿæ™‚ã¯ Section 1ã‹ã‚‰é–‹å§‹ã—ã€é‡è¦åº¦ã«å¿œã˜ã¦é©åˆ‡ãªå¯¾å¿œãƒ¬ãƒ™ãƒ«ã‚’é¸æŠã€‚å¿…ãšãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦å¯¾å¿œæ¼ã‚Œã‚’é˜²ãã“ã¨ã€‚å¯¾å¿œå®Œäº†å¾Œã¯å¿…ãšSection 5ã®äº‹å¾Œå¯¾å¿œã§ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²ã™ã‚‹ã“ã¨ã€‚